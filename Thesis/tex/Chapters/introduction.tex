\part{Introduction}
\begin{comment}
Many models of artificial markets resemble typical game theoretic models in that all trading is round based. Typically all agents receive the market information and evaluate their strategies once every round. Such models are very useful when all agents are more or less equally fast, since it is then reasonable to assume that they have access to the same information. 

The model proposed in this work is different from such models in that it assumes that agents generally do \textit{not} have access to the same information when they evaluate their strategies. 
\end{comment}

In other words, by assigning agents in either group a latency of a certain number of rounds, the model allows the analysis of the impact of agent speed to be quantitative rather than qualitative. Models of the qualitative kind are useful for answering broad questions such as ``do fast traders have an advantage over slow traders?' ' or ``do fast traders make the markets unstable?''. However, as the questions are qualitative, as must the answers necessarily be. Hence, the answers are likely to be along the lines of ``sometimes'', without providing any insight into which exact circumstances . After all, fast algorithmic traders are a fact of modern markets , and while it has both been shown that these traders make the markets more efficient \cite{keylist} and that high frequency traders can be linked to instabilities such as flash crashes, it is conceivable these pros and cons do not simply depend on the seed of the agents, but also on \textit{which} agents are fast, and \textit{how much faster} they are than other fast agents, etc. This line of thought was clearly expression in \cite{farmer2013ecological}, where the authors strongly advocate for the development of a taxonomy of modern trading strategies employed by algorithm traders, as the authors argue that a market should be be thought of as an ecological system. In order to do this, a model must necessarily be able to emulate a trading environment in which the traders all have speeds that are relative to each other. In other words, a model in which the speed of the agents are quantitative rather than qualitative. Hence, this work focuses strongly on emulating real-time delays in the flow of information as they would exist in the real world.


\section{Background}
One of the great challenges of science today is to model systems in which the system dynamics are influenced  human behavior. The purpose of trying to describe such systems through models is to obtain tools which allow prediction, and ultimately makes it possible to enforce control. Traditional economics tries to understand such systems, by using an analytic approach, which often limits the complexity of the model. In spite of these assumptions, classical economic theory has proven itself capable of modeling many of the dynamics of human society where the exchange of goods for money takes place, i.e., market places.
%, and to predict how the system will react to various stimuli. 

At its core, economic theory is mostly concerned with how large groups people can be expected to behave on average, by interacting with other human beings. As such, the theories are not suitable for explaining situations arising from recent technological developments:
\begin{description}
\item[Systems with human-machine interaction] Markets have changed drastically in the last few decades. The use of information technology to handle tasks such as trade execution has become the norm. The Internet carries a vast amount of news around the globe in a matter of milliseconds, and computers are ready to react at a moments notice every minute of every day. Thus the need of humans to constantly monitor markets in order to anticipate fast market changes has been replaced by the need to employ algorithms to perform such tasks. Furthermore, with the rapid development of artificial intelligence and soft computing, algorithms are now also involved in the process of make actual trading decisions. However, even though many of the tasks that before were performed by humans are now largely automatized, humans still play an important role in modern markets. After all, algorithms are (still) created by humans, although attempt are also made to partly automatize even this process: see \cite{allen1999using} and \cite{potvin2004generating}. Furthermore, humans still play a vital role in evaluating the significance of news, although (naturally) this process is also being increasingly automatized by trying to predict consensus from online news sources, such as newspaper articles, blogs and social networks: \cite{devitt2007sentiment}, \cite{koppel2006good}, \cite{godbole2007large}, \cite{bollen2011twitter}). No matter what the future of increasingly automatized markets will look like\footnote{The author envisions a scenario of ``Skynet vs. W. Buffet''}, there is no doubt that current markets are system where humans and machines interact with each other and a the financial markets. 
\item[Technology is the new cunning]ã€€Situations where a few, exceptional individuals are responsible for a large part of the aggregate activity
\end{description}
As for the first item, 

As for the second item, the financial sector has changed as well, due to the invention on a new set of trading strategies called high frequency trading. High frequency trading uses computers and algorithms to analyze market data and trade faster than any human can. By directly accessing the order book information which shows at which prices other traders are currently willing to trade, they are also able to get an accurate picture of the current market state. By placing themselves physically close to the markets (the practice know as co-location), they are able to do so at a very high time resolution. Again, by investing heavily in communication equipment, they are able to process large amounts of information and quickly reach trading decisions.

In other words, economic theory today needs to cope with a reality in which there are a relatively few number of traders who are exceptional in the sense that they have access to technology that other traders do not, and that they use that fact win over other humans traders and less sophisticated trading algorithms. Due to the increased complexity of the analysis required to understand such systems, and due to a number a violent financial crashes in recent years, some economists have started expressing an interest in the use of computational models to understand economic systems as a whole. A few such papers are mentioned in section \ref{section_relatedWork}.

In parallel, the idea of multi-agent systems has risen in the field of computer science. Because computers are increasingly linked together in networks, they interact with each other, and hence comprise a system in which their aggregated behavior can be analyzed. 

Computers, or rather the software that we call agents, are relatively simple to model. If the software is simple enough, it might not even require modeling, and the software agents can be plugged directly into a simulation engine. Much of the work in done in MAS carried out by researchers from the computer science community the field of multi-agent simulation (MAS) has been concerned with modeling and analyzing such system where machines interact with other machines. 
 
MAS is a well suited tool to deal with the complexities of the modern trading world, because it allows for the construction of models with complex dynamics. Naturally, the creation of realistic agent models is difficult. However, as is done in this paper, it is possible to capture essential characteristics of the problem under investigation. In this paper, we create a model of a simple trading environment with one market, and several agents trading on that market. The aim of creating this model is to find out how artificial markets behave when there is a communication delay between the agents and the market. The contents of this paper is as follows. First, in section \ref{section_relatedWork}, we summarize the main influences of this work, and explain a few of the ideas that were central to the development of our own model. Next, in section 

\section{Related work}\label{section_relatedWork}

This section contains a short summary of the literature that provided the main inspiration for this work. Due to the multi-disciplinary nature of the background of the researchers who contribute (economists, computer scientists, ecologists, sociologists, etc.), it is not within the scope of this section to give  comprehensive review of the literature. Rather, the aim of this section is to show which influences lie behind this work, and where this work tries to add new contributions.

\cite{chiwang2013investigating} proposes a round-based model in which a fast trader using a market maker strategy trades against a large number of slow traders, implemented as the stylized trader model laid out in \cite{chiarella2009impact}. The paper shows a link between the frequency with which the traders trade and their trading success. The notion of a trading frequency is also present in our model, as assign each agent with a time delay to the market which means that the agent can never trade faster than it takes for information to flow between itself and the market.

In \cite{johnson2012financial}, the authors show that as the time resolution with which information from stock market is observed is increased, the the distribution of price movements of the traded asset changes from the usually observed power law.  suggesting that the presence of very fast traders creates markets which behave in fundamentally different ways. The authors then proceed to discuss the phenomenon of strategy crowding, which they argue is one reason why many flash-crashes can be observed in recent years. The crux of the argument is that the faster the agents have to be, the less information they have to trade on, and this means that there are only so possible conclusions that can be drawn. As the agents react similarly, they can cause crashes, especially if those agents are responsible for trading large volumes. Our model adds an extra condition for this to happen. Not only must the agents be similar, but they must also receive the same information at the same time, which may or may not happen.

In cite \cite{biais2011high}, the authors point out that the share of the volume traded by high frequency traders vary widely from market to market, but that in some markets it is estimated to be as high as 70\%. The same paper also goes to great lengths to specify exactly what high frequency trading is, and lists a number of defining characteristics. A few of them are ``Very high number of orders'', ``rapid order cancellations'', ``profit from buying and selling (as middlemen)'', ``low latency requirement'', ``use of co-location/proximity services and individual data feeds''. These are (some of) the typical characteristics that high frequency traders exhibit, and they have all been replicated by our model. If we want to understand markets in which high frequency trading is taking place, these characteristics should be replicated, rather than trying to mimic specific strategies which are used in the real world. Another argument for this is that, unlike the more traditional chartist strategies, modern algorithmic trading trading strategies use complex probabilistic models, which are very difficult (if not impossible) to reverse-engineer. In many cases, the only way to judge the efficacy of a trading algorithm is to implement several types of algorithms and let them trade against each other, as was done in \cite{izumi2009evaluation}.

Because of the high degree of secrecy surrounding which algorithms are actually being used for high frequency trading, and since the practice is relatively new, \cite{mcgowan2010rise} argues that there is a general lack of knowledge about the topic, even among professionals in the financial field. To remedy that fact, it tries to establish a broad taxonomy of strategies employed by high frequency traders, and basically divides them into market making strategies, arbitrage strategies, and market rebate trading strategies.

\cite{farmer2013ecological} is another work arguing for a taxonomy of the trading strategies, but does so from an ecological perspective by assigning roles of prey and predator to traders. This way of thinking is closely related to the discussion of whether or not HFT is beneficial or harmful to markets, as it is intuitive to think of HFTs as the predators and other traders as they prey. The default assumption seems to be that it is not beneficial, partly because of the large profits, but some findings seem to indicate that HFT actually improve liquidity in markets, and argue that the profit gained by the HFT is the cost imposed on other traders. Indeed, since financial institutions expected of employing HFTs themselves seem to affected by flash crashes in their company stock, as was pointed out in \cite{johnson2012financial}. \cite{mcinish2012strategic} indirectly presents an argument for this notion of predator vs. prey. It is interested in the phenomenon of flickering quotes, i.e., small, momentary differences in trade prices between markets. The paper uses a simple, round-based model, and presents equations for when the fast traders show use their speed advantage to deliberately sell at sub-prime prices to the slow traders.

For works on the MAS methodology in general, see \cite{davidsson2001multi, gilbert2004agent, macal2005tutorial}. A review of early works in the field of simulated finance can be found in \cite{lebaron2000agent} and provides a good introduction to the field. For a few other works on agent-based computational economics, see \cite{raberto2001agent, tesfatsion2002agent, tesfatsion2006agent, lebaron2001builder}.

In summary, much interesting work, which aims to understand the role and impact of high frequency trading and algorithmic trading in general, has been done. Some works try to reach conclusions by analyzing real stock-data, whereas other papers approach the problem differently by first building a model, and then perform experiments to see if realistic dynamics can be replicated by the model. The latter approach is typical for papers in the MAS field, and this thesis belongs to that category is one such paper. However, to the limit of the author's knowledge, no MAS-model has yet attempted a real-time simulation approach as is proposed in this paper. Since the timing of trading is very important for high frequency trading, we believe that a model which simulates that timing is necessary.

