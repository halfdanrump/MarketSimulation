\part{Background}
\begin{comment}
Many models of artificial markets resemble typical game theoretic models in that all trading is round based. Typically all agents receive the market information and evaluate their strategies once every round. Such models are very useful when all agents are more or less equally fast, since it is then reasonable to assume that they have access to the same information. 

The model proposed in this work is different from such models in that it assumes that agents generally do \textit{not} have access to the same information when they evaluate their strategies. 
\end{comment}



\section{Introduction}
One of the great challenges of science today is to model systems in which the system dynamics are influenced  human behavior. The purpose of trying to describe such systems through models is to obtain tools which allow prediction, and ultimately makes it possible to enforce control.

Traditional economics tries to understand such systems, by using an analytic approach, requiring many, simplifying assumptions. In spite of these assumptions, classical economic theory has proven itself capable of modeling many of the dynamics of human society where the exchange of goods for money takes place
%, and to predict how the system will react to various stimuli. 

At its core, economic theory is mostly concerned with how large groups people can be expected to behave on average, by interacting with other human beings. As such, the theories are not suitable for explaining situations arising from recent technological developments. Of interest to this papers are especially two such cases:
\begin{enumerate}
\item Situations where humans and machines interact.
\item Situations where a few, exceptional individuals are responsible for a large part of the aggregate activity
\end{enumerate}
In terms of the first item, the financial sector has changed drastically during the last few decades. First of all, the use of computers to handle mundane tasks is no longer news, and has become commonplace. Furthermore, with the rapid development of artificial intelligence and soft computing, algorithms are now also involved in the trade decision process itself, rather than just doing simple trade execution tasks. Hence, rather than being a system where humans interact with humans and markets, the current financial system is one in which humans and machines interact with markets, humans and machines. 

As for the second item, the financial sector has changed as well, due to the invention on a new set of trading strategies called high frequency trading. High frequency trading uses computers and algorithms to analyze market data and trade faster than any human can. By directly accessing the order book information which shows at which prices other traders are currently willing to trade, they are also able to get an accurate picture of the current market state. By placing themselves physically close to the markets (the practice know as co-location), they are able to do so at a very high time resolution. Again, by investing heavily in communication equipment, they are able to process large amounts of information and quickly reach trading decisions.

In other words, economic theory today needs to cope with a reality in which there are a relatively few number of traders who are exceptional in the sense that they have access to technology that other traders do not, and that they use that fact win over other humans traders and less sophisticated trading algorithms. Due to the increased complexity of the analysis required to understand such systems, and due to a number a violent financial crashes in recent years, some economists have started expressing an interest in the use of computational models to understand economic systems as a whole. A few such papers are mentioned in section \ref{section_relatedWork}.

In parallel, the idea of multi-agent systems has risen in the field of computer science. Because computers are increasingly linked together in networks, they interact with each other, and hence comprise a system in which their aggregated behavior can be analyzed. 

Computers, or rather the software that we call agents, are relatively simple to model. If the software is simple enough, it might not even require modeling, and the software agents can be plugged directly into a simulation engine. Much of the work in done in MAS carried out by researchers from the computer science community the field of multi-agent simulation (MAS) has been concerned with modeling and analyzing such system where machines interact with other machines. 
 
MAS is a well suited tool to deal with the complexities of the modern trading world, because it allows for the construction of models with complex dynamics. Naturally, the creation of realistic agent models is difficult. However, as is done in this paper, it is possible to capture essential characteristics of the problem under investigation. In this paper, we create a model of a simple trading environment with one market, and several agents trading on that market. The aim of creating this model is to find out how artificial markets behave when there is a communication delay between the agents and the market. The contents of this paper is as follows. First, in section \ref{section_relatedWork}, we summarize the main influences of this work, and explain a few of the ideas that were central to the development of our own model. Next, in section 

\section{Related work}\label{section_relatedWork}

%\bibitem{chiWang} Chi Wang, Kiyoshi Izumi, Takanobu Mizuta and Shinobu Yoshimura:
%\bibitem{riseOfComputerizedTrading} Michael J. McGowan:
%\bibitem{strategicLiquiditySupply} Thomas McInish and James Upson:
%\bibitem{financialBlackSwans} Niel Johnson, Guannan Zhao, Eric Hunsader, Jing Meng, Amith Ravindar, Spencer Carran and Brian Tivnan: 
%\bibitem{evaluationOfAutomated}
%\bibitem{theImpactOfHeterogenous}
%\bibitem{highFrequencyTrading}
%\bibitem{anEcologicalPerspective}
Artificial market simulation is a popular field with many different viewpoints. Due to the multi-disciplinary nature of the background of the researchers who contribute (economists, computer scientists, ecologists, sociologists, etc.), it is not within the scope of this section to give  comprehensive review of the literature. Rather, the aim of this section is to show which influences lie behind this work, and where we have tried to add new contributions.

\cite{chiWang} proposes a round-based model in which a fast trader using a market maker strategy trades against a large number of slow traders, implemented as the stylized trader model laid out in \cite{theImpactOfHeterogenous}. The paper shows a link between the frequency with which the traders trade and their trading success. The notion of a trading frequency is also present in our model, as assign each agent with a time delay to the market which means that the agent can never trade faster than it takes for information to flow between itself and the market.

In \cite{financialBlackSwans}, the authors show that as the time resolution with which information from stock market is observed is increased, the the distribution of price movements of the traded asset changes from the usually observed power law.  suggesting that the presence of very fast traders creates markets which behave in fundamentally different ways. The authors then proceed to discuss the phenomenon of strategy crowding, which they argue is one reason why many flash-crashes can be observed in recent years. The crux of the argument is that the faster the agents have to be, the less information they have to trade on, and this means that there are only so possible conclusions that can be drawn. As the agents react similarly, they can cause crashes, especially if those agents are responsible for trading large volumes. Our model adds an extra condition for this to happen. Not only must the agents be similar, but they must also receive the same information at the same time, which may or may not happen.



In cite \cite{highFrequencyTrading}, the authors point out that the share of the volume traded by high frequency traders vary widely from market to market, but that in some markets it is estimated to be as high as 70\%. The same paper also goes to great lengths to specify exactly what high frequency trading is, and lists a number of defining characteristics. A few of them are ``Very high number of orders'', ``rapid order cancellations'', ``profit from buying and selling (as middlemen)'', ``low latency requirement'', ``use of co-location/proximity services and individual data feeds''. These are (some of) the typical characteristics that high frequency traders exhibit, and they have all been replicated by our model. If we want to understand markets in which high frequency trading is taking place, these characteristics should be replicated, rather than trying to mimic specific strategies which are used in the real world. Another argument for this is that, unlike the more traditional chartist strategies, modern algorithmic trading trading strategies use complex probabilistic models, which are very difficult (if not impossible) to reverse-engineer. In many cases, the only way to judge the efficacy of a trading algorithm is to implement several types of algorithms and let them trade against each other, as was done in \cite{evaluationOfAutomated}.

Because of the high degree of secrecy surrounding which algorithms are actually being used for high frequency trading, and since the practice is relatively new, \cite{riseOfComputerizedTrading} argues that there is a general lack of knowledge about the topic, even among professionals in the financial field. To remedy that fact, it tries to establish a broad taxonomy of strategies employed by high frequency traders, and basically divides them into market making strategies, arbitrage strategies, and market rebate trading strategies.

\cite{anEcologicalPerspective} is another work arguing for a taxonomy of the trading strategies, but does so from an ecological perspective by assigning roles of prey and predator to traders. This way of thinking is closely related to the discussion of whether or not HFT is beneficial or harmful to markets, as it is intuitive to think of HFTs as the predators and other traders as they prey. The default assumption seems to be that it is not beneficial, partly because of the large profits, but some findings seem to indicate that HFT actually improve liquidity in markets, and argue that the profit gained by the HFT is the cost imposed on other traders. Indeed, since financial institutions expected of employing HFTs themselves seem to affected by flash crashes in their company stock, as was pointed out in \cite{financialBlackSwans}. \cite{strategicLiquiditySupply} indirectly presents an argument for this notion of predator vs. prey. It is interested in the phenomenon of flickering quotes, i.e., small, momentary differences in trade prices between markets. The paper uses a simple, round-based model, and presents equations for when the fast traders show use their speed advantage to deliberately sell at sub-prime prices to the slow traders.

In summary, much interesting work has been done in order to understand the role and impact of high frequency trading, and algorithmic trading in general. Some works try to reach conclusions by analyzing real stock-data, whereas other papers approach the problem differently by first building a model, and then perform experiments to see if realistic dynamics can be replicated by the model. The latter approach is typical for papers in the MAS field, and this paper is one such paper. However, to the limit of the author's knowledge, no MAS-model has yet attempted a real-time simulation approach as is proposed in this paper. Since high the timing of trading is very important for high frequency trading, we believe that a model which simulates that timing is necessary.

